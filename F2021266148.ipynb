{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a759019d-8632-4a7f-a417-703bd4e25fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Poster cannot be converted to float and will be dropped.\n",
      "Column Title cannot be converted to float and will be dropped.\n",
      "Column Cast cannot be converted to float and will be dropped.\n",
      "Column Votes cannot be converted to float and will be dropped.\n",
      "Column Description cannot be converted to float and will be dropped.\n",
      "Column Review Count cannot be converted to float and will be dropped.\n",
      "Column Review Title cannot be converted to float and will be dropped.\n",
      "Column Review cannot be converted to float and will be dropped.\n",
      "     Year  Certificate  Duration (min)  Genre  Rating  Metascore\n",
      "0  2023.0           20           115.0    228     6.4       67.0\n",
      "1  2023.0           19           145.0     12     7.3       66.0\n",
      "2  2023.0           19            97.0    188     5.5       42.0\n",
      "3  2023.0           19           126.0     22     7.3       73.0\n",
      "4  2023.0           20           131.0    400     7.7       82.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "file_path = r\"C:\\Users\\abeer\\Downloads\\New folder\\imdb-movies-dataset.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# List of columns to drop\n",
    "columns_to_drop = ['Poster_Link', 'Series_Title', 'Overview', 'Director', 'Star1', 'Star2', 'Star3', 'Star4']\n",
    "\n",
    "# Check which columns are present in the DataFrame\n",
    "columns_to_drop_existing = [column for column in columns_to_drop if column in df.columns]\n",
    "\n",
    "# Drop the existing columns\n",
    "df = df.drop(columns=columns_to_drop_existing)\n",
    "\n",
    "# Handle missing values and column transformations if they exist\n",
    "if 'Gross' in df.columns:\n",
    "    df['Gross'] = df['Gross'].str.replace(',', '').astype(float)\n",
    "    df['Gross'].fillna(df['Gross'].mean(), inplace=True)\n",
    "\n",
    "if 'Meta_score' in df.columns:\n",
    "    df['Meta_score'].fillna(df['Meta_score'].mean(), inplace=True)\n",
    "\n",
    "if 'Certificate' in df.columns:\n",
    "    df['Certificate'].fillna(df['Certificate'].mode()[0], inplace=True)\n",
    "\n",
    "if 'Released_Year' in df.columns:\n",
    "    df['Released_Year'].fillna(df['Released_Year'].mode()[0], inplace=True)\n",
    "    df = df[df['Released_Year'] != 'PG']\n",
    "    df['Released_Year'] = df['Released_Year'].astype(int)\n",
    "\n",
    "if 'Runtime' in df.columns:\n",
    "    df['Runtime'] = df['Runtime'].str.replace(' min', '').astype(int)\n",
    "\n",
    "# Encode categorical variables\n",
    "if 'Genre' in df.columns:\n",
    "    le_genre = LabelEncoder()\n",
    "    df['Genre'] = le_genre.fit_transform(df['Genre'])\n",
    "\n",
    "if 'Certificate' in df.columns:\n",
    "    le_certificate = LabelEncoder()\n",
    "    df['Certificate'] = le_certificate.fit_transform(df['Certificate'])\n",
    "\n",
    "# Ensure all columns are numeric before scaling\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object':\n",
    "        try:\n",
    "            df[column] = df[column].astype(float)\n",
    "        except ValueError:\n",
    "            print(f\"Column {column} cannot be converted to float and will be dropped.\")\n",
    "            df = df.drop(columns=[column])\n",
    "\n",
    "# Define independent variables (features) and dependent variable (target)\n",
    "if 'Certificate' in df.columns:\n",
    "    X = df.drop(columns=['Certificate'])\n",
    "    y = df['Certificate']\n",
    "else:\n",
    "    X = df.copy()\n",
    "    y = pd.Series([])\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "if not y.empty:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the first few rows of the processed dataset\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c96e7f06-132b-475b-9752-e0056cb3ee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Logistic Regression': {'accuracy': 0.4185, 'precision': 0.25385286359013476, 'recall': 0.4185, 'f1_score': 0.27842423333403976}, 'Decision Tree': {'accuracy': 0.349, 'precision': 0.35883740489126603, 'recall': 0.349, 'f1_score': 0.3534543521881143}, 'Random Forest': {'accuracy': 0.4715, 'precision': 0.40703953897192147, 'recall': 0.4715, 'f1_score': 0.41702815671181315}, 'SVM': {'accuracy': 0.433, 'precision': 0.37793348348410744, 'recall': 0.433, 'f1_score': 0.297340528107486}, 'k-NN': {'accuracy': 0.3985, 'precision': 0.35580499151417294, 'recall': 0.3985, 'f1_score': 0.3648125310252858}}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Dictionary to store the evaluation metrics for each model\n",
    "results = {}\n",
    "\n",
    "# Function to evaluate a model\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        'recall': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        'f1_score': f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "results['Logistic Regression'] = evaluate_model(log_reg, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Decision Tree Classifier\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "results['Decision Tree'] = evaluate_model(decision_tree, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Random Forest Classifier\n",
    "random_forest = RandomForestClassifier()\n",
    "results['Random Forest'] = evaluate_model(random_forest, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "svm = SVC()\n",
    "results['SVM'] = evaluate_model(svm, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# k-Nearest Neighbors (k-NN)\n",
    "knn = KNeighborsClassifier()\n",
    "results['k-NN'] = evaluate_model(knn, X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9429309-53c4-4975-a31d-513da5791b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "accuracy: 0.4185\n",
      "precision: 0.2539\n",
      "recall: 0.4185\n",
      "f1_score: 0.2784\n",
      "\n",
      "\n",
      "Model: Decision Tree\n",
      "accuracy: 0.3490\n",
      "precision: 0.3588\n",
      "recall: 0.3490\n",
      "f1_score: 0.3535\n",
      "\n",
      "\n",
      "Model: Random Forest\n",
      "accuracy: 0.4715\n",
      "precision: 0.4070\n",
      "recall: 0.4715\n",
      "f1_score: 0.4170\n",
      "\n",
      "\n",
      "Model: SVM\n",
      "accuracy: 0.4330\n",
      "precision: 0.3779\n",
      "recall: 0.4330\n",
      "f1_score: 0.2973\n",
      "\n",
      "\n",
      "Model: k-NN\n",
      "accuracy: 0.3985\n",
      "precision: 0.3558\n",
      "recall: 0.3985\n",
      "f1_score: 0.3648\n",
      "\n",
      "\n",
      "The best model is: Random Forest\n"
     ]
    }
   ],
   "source": [
    "# Print the results in a formatted manner\n",
    "for model, metrics in results.items():\n",
    "    print(f\"Model: {model}\")\n",
    "    for metric, score in metrics.items():\n",
    "        print(f\"{metric}: {score:.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Determine the best model based on a chosen metric (e.g., F1-score)\n",
    "best_model = max(results, key=lambda x: results[x]['f1_score'])\n",
    "print(f\"The best model is: {best_model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6cf817-e514-4689-87e7-00fcf548392b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
